{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech Pedestrian Annotation\n",
    "\n",
    "The Caltech Pedestrians dataset (http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/) is separated into images and annotations.\n",
    "\n",
    "Using a third-party converter (https://github.com/mitmul/caltech-pedestrian-dataset-converter), I have the extracted the annotations into a massive JSON file. I will be exploring the annotations in order to get a better feel for the data, and to pick a subset of images I would like to train on.\n",
    "\n",
    "In particular, the annotations are stored in `.vbb` format, which stands for \"video bounding box.\" Someone on the internet gives the following explanation of the format:\n",
    "\n",
    "```\n",
    "A video bounding box (vbb) annotation stores bounding boxes (bbs) for\n",
    "objects of interest. The primary difference from a static annotation is\n",
    "that each object can exist for multiple frames, ie, a vbb annotation not\n",
    "only provides the locations of objects but also tracking information. A\n",
    "vbb annotation A is simply a Matlab struct. It contains data per object\n",
    "(such as a string label) and data per object per frame (such as a bb).\n",
    "Each object is identified with a unique integer id.\n",
    "\n",
    "Data per object (indexed by integer id) includes the following fields:\n",
    " init - 0/1 value indicating whether object w given id exists\n",
    " lbl  - a string label describing object type (eg: 'pedestrian')\n",
    " str  - the first frame in which object appears (1 indexed)\n",
    " end  - the last frame in which object appears (1 indexed)\n",
    " hide - 0/1 value indicating object is 'hidden' (used during labeling)\n",
    "\n",
    "Data per object per frame (indexed by frame and id) includes:\n",
    " pos  - [l t w h]: bb indicating predicted object extent\n",
    " posv - [l t w h]: bb indicating visible region (may be [0 0 0 0])\n",
    " occl - 0/1 value indicating if bb is occluded\n",
    " lock - 0/1 value indicating bb is 'locked' (used during labeling)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../CaltechPedestrians/data/annotations.json') as f:\n",
    "    raw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nFrame\n",
      "maxObj\n",
      "log\n",
      "logLen\n",
      "altered\n",
      "frames\n"
     ]
    }
   ],
   "source": [
    "for k, v in raw['set00']['V000'].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 371,\n",
       "  'hide': 0,\n",
       "  'id': 2,\n",
       "  'init': 1,\n",
       "  'lbl': 'person',\n",
       "  'lock': 0,\n",
       "  'occl': 0,\n",
       "  'pos': [225.3247422320086,\n",
       "   136.01476564957534,\n",
       "   5.606859337317815,\n",
       "   11.767162105483848],\n",
       "  'posv': [0, 0, 0, 0],\n",
       "  'str': 69}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['set00']['V000']['frames']['88']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
